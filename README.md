# iFabric

This repo begins as a clone from https://github.com/p4lang/tutorials. Thanks for everyone involved in P4 community which gave me the opportunity to learn and start working of this project. Also big thanks for everyone that took time to listen to my ideas and helped me shaped them better.


The following document goes as follows:
  1. **Current idea** :
   This section should give a good outline of what's currently in the scope of the project. The idea is still under heavy development and changes quite often so little is set in stone.
  
  2. **What's implemented** :
  What is the current state of the project, it's possibilities and using what technologies.
  
  3. **Perceived values of the solution** :
  What I think are the values in this project and what made me pursue it.
  
  4. **Possible problems** :
  What I currently see as biggest problems of the solution and how they might be addressed.
  
  5. **Possible extensions** :
  What I see as possible extensions of this project if it gets operational.

## Current idea

In current idea *iFabric* is SDN packet-based network that uses P4 switches for data-plane and reinforcement learning algorithms for control-plane. The *iFabric* can be characterized by: high-performance, resilience, flexibility/ease of configuration and quickness of deployment.

Here's briefly how the current idea supports each of those characteristics. They are explained in greater detail later.
1. **High-performance:**
  The network is based on P4 hardware and small pipeline that should allow great performance.
  
2. **Resilience:**
  The network is able to support any topology we wish use. Devices connected to the network can be connected in any way they want.
  
3. **Flexibility of configuration:**
  For backwards-compatibility with the infrastracture, the network can be configured in such a way that its operation closely resembles current networks (*TCP/IP*, *Fibre Channel etc.*) and forwarding is done using standard protocols but it might use brand new protocols that *Operator* can define for his infrastracture.
  
4. **Ease of configuration:**
  The configuration should be generated from as little information as possible. In standard scenarios this can be achieved via templates that would define ready to use protocols and topologies that see most use. The network could be thought of as *Infrastracture as a Code* so that in the future the configuration could be automatically generated by an application that needs network to communicate with other devices. More on that idea in **Possible extensions** . 
  
5. **Quickness of deployment:**
  All processes of deployment should be made as automated as possible, that is, after connecting the hardware and providing high-level configuration the network will need time to train itself which will probably be the longest process. It is still unclear what timespans we could be looking at (minutes, days, weeks, months) but that depends mostly upon ever-improving computing and algorithms. With current State-of-Art I believe few weeks should be feasible but that's what I see as entry point not a ceiling. More on that in **Control-plane** .
  

The core of the idea currently consists of three structures briefly introduced here and expanded upon later:
- **Topology**
- **Configuration**
- **Control-plane**
  

The structures that make the iFabric are presented with provided example of how *iFabric* might implement *IP/MAC* network. Later, I show other sample *iFabric* network implementation to highlight the flexibility of configuration.

### 1. Topology:

Topology is made out of *P4* switches, SDN controllers and *Nodes* connected to them. On hardware level, we can currently distinguish two types of links: switch-interconnections and *Nodes* to switches connections. . For *Node* it means that, it can be connected to any switchport on any switch with as many links per switch as it needs. 

Nodes we might have in our first example could be:
- *email_server*
- *database_server*
- *firewall*
- *website_1*
- *website_dr_1*
- *website_dr_2*
  
Nodes can be put into Groups. We should be able to put Node into many groups at once for example:
1. Websites:
    - *website_1*
    - *website_dr_1*
    - *website_dr_2*
2. DR:
    - *website_dr_1*
    - *website_dr_2*
3. Servers:
    - *email_server*
    - *database_server*

### 2. Configuration:
Before the *iFabric* starts 
  - _flows, ( F = {flow_1, flow_2 ... flow_n} )_
  - _policy, ( Pol = {pol_1, pol_2 ... pol_3} )_

Both of those should be as user-friendly and automated in their generation as possible.

Flows in an example IP/MAC fabric we might want to configure could look like:
_F = {flow_to_firewall_ip, flow_to_server1, flow_to_servers_1_to_20 ...}_

Policies we could define in this fabric could be:

_Pol = {}_

#### Flow - definition:
Named Set of Protocol Fields: ProtF_Set = {ProtF_1, ..., ProtF_n}, and set of ranges for protocol fields: ProtF_Ranges(ProtF_x) = {(ProtF_Low1, ProtF_High1), (ProtF_Low2, ProtF_High2) ... (ProtF_LowN, ProtF_HighN)} for ProtF_x from ProtF_Set



Protocol Field is any data that we can define using P4. For our IP/MAC fabric we could go with:
```
typedef bit<48> macAddr_t;

header Ethernet_t {
    macAddr_t dstAddr;
    macAddr_t srcAddr;
    bit<16>   etherType;
}


typedef bit<32> ip4Addr_t;

header IPv4_t {
    bit<4>    version;
    bit<4>    ihl;
    bit<8>    diffserv;
    bit<16>   totalLen;
    bit<16>   identification;
    bit<3>    flags;
    bit<13>   fragOffset;
    bit<8>    ttl;
    bit<8>    protocol;
    bit<16>   hdrChecksum;
    ip4Addr_t srcAddr;
    ip4Addr_t dstAddr;
}
```
In this example Protocol Fields we could use would f.g. be IPv4.dstAddr and Ethernet.dstAddr.
Ranges we could define as f.g. ProtF_Ranges(IPv4.dstAddr) = { (10.0.0.1, 10.0.0.26) }

Flows in this network could look like:
F = {flow_to_firewall_ip, flow_to_server1 , flow_to_servers_1_to_20 ...}

And they could look like:
flow_to_firewall_ip = {protocol: IPv4_
  
But we could go with something like:
```
typedef bit<256> server_ID;

header MyServerFarm_t {
    server_ID   dstID;
    server_ID   srcID;
    bit<32>   someServerPolicyField;
    bit<32>   processOnDstServerThatNeedsThisData;
}

```

And assume that host from their NICs send data with this header instead of whole TCP/IP stack. We can use as many headers/protocols (as hardware allows). They can be new or old ones combined in any way. (at least i assume that all P4 targets support that by default, which I believe they do)


Prot_Low and Prot_High are bit values that determine the span of values that we look at in the protocol.

Each flow also needs a priority that determines what happens if ranges from the flows overlaps.



#### Policy - definition

## 2. Configuration

## 3. Control-plane


